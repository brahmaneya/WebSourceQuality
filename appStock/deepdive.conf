deepdive {

  db.default {
    driver: "org.postgresql.Driver"
    url: "jdbc:postgresql://"${PGHOST}":"${PGPORT}"/"${DBNAME} # "
    user: ${PGUSER}
    password: ${PGPASSWORD}
    dbname: ${DBNAME}
    host: ${PGHOST}
    port: ${PGPORT}
  }

  # Put your variables here
  schema.variables {
    stock_truth.is_true: Boolean
    source_stock_truth.is_true: Boolean
  }

  # Put your extractors here
  extraction.extractors {

    # Extractor 1: Clean output tables of all extractors
    ext_clear_table {
      style: "sql_extractor"
      sql: """
        DELETE FROM stock_truth;
        DELETE FROM source_stock_truth;
        """
    }

    ext_populate_stock_true {
      style: "sql_extractor"
      sql: """
        INSERT INTO stock_truth
        SELECT stock_symbol || '-' || volume, true
        FROM stock_input
	WHERE is_true = 'true'
        """
      dependencies: ["ext_clear_table"]
    }

    ext_populate_stock_false {
      style: "sql_extractor"
      sql: """
        INSERT INTO stock_truth
        SELECT stock_symbol || '-' || volume, false
        FROM stock_input
	WHERE is_true = 'false'
        """
      dependencies: ["ext_clear_table"]
    }

    ext_populate_stock_unlabeled {
      style: "sql_extractor"
      sql: """
        INSERT INTO stock_truth
        SELECT stock_symbol || '-' || volume
        FROM stock_input
	WHERE is_true = 'N/A'
        """
      dependencies: ["ext_clear_table"]
    }
          
    ext_source_stock_truth {
      style: "sql_extractor"
      sql: """
        INSERT INTO source_stock_truth
        SELECT source_id, stock_symbol || '-' || stock_volume, is_true
        FROM source_stock_input
        """
      dependencies: ["ext_clear_table"]
    }

  }

  inference.factors: {

    # We require developers to select: 
    #   - reserved "id" column, 
    #   - variable column, 
    #   - weight dependencies,
    # for variable tables.
    f_source_stock_true {
      input_query: """
        SELECT  stock_truth.id AS "stock_truth.id",
                source_stock_truth.id AS "source_stock_truth.id",
		stock_truth.is_true AS "stock_truth.is_true",
		source_stock_truth.is_true as "source_stock_truth.is_true",
                source_stock_truth.source_id AS "source_stock_truth.source_id"
        FROM    source_stock_truth, 
                stock_truth 
        WHERE   source_stock_truth.stock_tuple_id = stock_truth.stock_tuple_id
        """
      function: "Equal(source_stock_truth.is_true,stock_truth.is_true)"
      weight: "?(source_stock_truth.source_id)"
    }

    f_source_stock_feature_true {
      input_query: """
	SELECT  stock_truth.id AS "stock_truth.id",
                source_stock_truth.id AS "source_stock_truth.id",
                stock_truth.is_true AS "stock_truth.is_true",
                source_stock_truth.is_true as "source_stock_truth.is_true",
                source_stock_truth.source_id AS "source_stock_truth.source_id"
		source_features.feature AS "source_features.feature"
        FROM    source_stock_truth,source_features,
                stock_truth
        WHERE   source_stock_truth.stock_tuple_id = stock_truth.stock_tuple_id
	AND	source_stock_truth.source_id = source_features.source_id
        """
      function: "Equal(source_stock_truth.is_true,stock_truth.is_true)"
      weight: "?(source_features.feature)"
    }


 }     

  # # An example of how to use the last factor graph:
  # pipeline.relearn_from: ${DEEPDIVE_HOME}"/out/2014-04-19T190341/"

  # # Default is to use the full pipeline, equivalent to:
   #pipeline.run: "han_features"
   pipeline.run: "han"
   pipeline.pipelines.han: [
     "ext_clear_table",
     "ext_populate_stock_true",
     "ext_populate_stock_false",
     "ext_populate_stock_unlabeled",
     "ext_source_stock_truth",
     "f_source_stock_true"
     ]
    pipeline.pipelines.han_features: [
     "ext_clear_table",
     "ext_populate_stock_true",
     "ext_populate_stock_false",
     "ext_populate_stock_unlabeled",
     "ext_source_stock_truth",
     "f_source_stock_feature_true"
     ]
    pipeline.pipelines.pos: [
     "ext_clear_table",
     "ext_labeled_tuple_truth",
     "ext_unlabeled_tuple_truth",
     "ext_source_outputs_input",
     "f_source_output_true",
     "f_source_output_false"
     ]
   pipeline.pipelines.extractors: [
     "ext_clear_table",
     "ext_labeled_tuple_truth",
     "ext_unlabeled_tuple_truth",
     "ext_source_books",#
     "ext_source_book_authors",#
     "ext_source_outputs_input",
     "ext_source_negations",#
     ]

  # # Specify a holdout fraction to hold out randomly
   calibration.holdout_fraction: 0.2

  # A more scientific way is to hold out by sentence:
  #  calibration.holdout_query:"""
  #    DROP TABLE IF EXISTS holdout_sentence_ids CASCADE; 

  #    CREATE TABLE holdout_sentence_ids AS 
  #    SELECT sentence_id FROM sentences WHERE RANDOM() < 0.25;

  #    INSERT INTO dd_graph_variables_holdout(variable_id)
  #    SELECT id FROM has_spouse WHERE sentence_id IN
  #    (SELECT * FROM holdout_sentence_ids);
  #  """

  # You may also try tuning sampler arguments:
  #sampler.sampler_args: "-l 1000 -s 1 -i 1000 --alpha 0.1 --diminish 0.99 -n 100"
  sampler.sampler_cmd: "sampler-dw-new em"
  #sampler.sampler_cmd: "sampler-dw-new gibbs"
  sampler.sampler_args: "-n 20 -l 1000 -s 1 -i 1000 --alpha 0.1 --diminish 0.99"
}
