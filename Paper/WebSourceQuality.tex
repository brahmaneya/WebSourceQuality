\documentclass{sig-alternate}
\usepackage{graphicx}
\usepackage{balance}  % for  \balance command ON LAST PAGE  (only there!)
\usepackage{enumitem}
\usepackage{times}
\usepackage{subfigure}
\let\proof\relax
\let\endproof\relax
\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx,color}
\usepackage{verbatim}
\usepackage{framed}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{framed}
\usepackage[normalem]{ulem}
\usepackage[export]{adjustbox}


\usepackage[font={small,it}]{caption}

\renewcommand{\baselinestretch}{1.0}

\renewcommand*\ttdefault{cmvtt}
\usepackage[T1]{fontenc}

% \usepackage{floatrow}
% \floatsetup[table]{font=scriptsize}
% \renewcommand\FBbskip{-10pt}


\newtheorem*{theorem*}{Theorem}
\newtheorem{theorem}{Theorem}
\newtheorem*{lemma*}{Lemma}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{example}[definition]{Example}
\newcounter{prob}
\newtheorem{problem}[prob]{Problem}

\newcommand{\agp}[1]{\textcolor{green}{Aditya: #1}}
\newcommand{\mrj}[1]{\textcolor{red}{#1}}
\newcommand{\mrjdel}[1]{\textcolor{red}{\sout{#1}}}
\newcommand{\logit}{\mathrm{logit}}

\newcommand{\squishlist}{
   \begin{list}{$\bullet$}
    { \setlength{\itemsep}{0pt}
      \setlength{\parsep}{2pt}
      \setlength{\topsep}{2pt}
      \setlength{\partopsep}{0pt}
    }
}
\newcommand{\stitle}[1]{\vspace{0.5em}\noindent\textbf{#1}}
\newcommand{\squishend}{\end{list}}
\newcommand{\eat}[1]{}
\newcommand{\papertext}[1]{#1}
\newcommand{\techreporttext}[1]{}

\newcommand{\calD}{\mathcal{D}\xspace}

\newenvironment{denselist}{
    \begin{list}{\small{$\bullet$}}%
    {\setlength{\itemsep}{0ex} \setlength{\topsep}{0ex}
    \setlength{\parsep}{0pt} \setlength{\itemindent}{0pt}
    \setlength{\leftmargin}{1.5em}
    \setlength{\partopsep}{0pt}}}%
    {\end{list}}

\makeatletter
\def\@copyrightspace{\relax}
\makeatother

\begin{document}

\title{Web Source Evaluation}
\numberofauthors{3} 
\author{
\alignauthor
Manas Joglekar\\
       \affaddr{Stanford University}\\
%       \affaddr{353 Serra Mall}\\
%	   \affaddr{Stanford, California 94305}\\
       \email{manasrj@stanford.edu}
\alignauthor
Hector Garcia-Molina\\
       \affaddr{Stanford University}\\
%       \affaddr{353 Serra Mall}\\
%	   \affaddr{Stanford, California 94305}\\
       \email{hector@cs.stanford.edu}
\alignauthor 
Aditya Parameswaran\\
       \affaddr{University of Illinois (UIUC)}\\
%       \affaddr{Champaign, Illinois 61820}\\
       \email{adityagp@illinois.edu}
}
\maketitle

\begin{abstract}
\end{abstract}

% extractor errors should count against source, because source is not readable (our data example, with bad formats in sources).
% jiawei han's asusmption vs out assumption, has to do with the semantics of sources, does a sources list 'favourite books' (then han's assumption), or claim to list all books. Overall, it may make sense to have the source-tuple candidate pairs (not output pairs) be part of input.

\section{Introduction}
In this work, we consider the problem of web source quality evaluation. Knowledge bases like the Google Knowledge Vault~\cite{Dong:2014:KVW:2623330.2623623}, or ones constructed using DeepDive~\cite{Niu_deepdive:web-scale}, rely on data mined from a large set of data sources, including webpages, journal papers, articles, and so on. These systems run extractors on the sources to extract structured data in form of `tuples' from them. Multiple sources can give us the same tuple, or possibly inconsistent tuples. If we extract a tuple $t$ from a source, we say that the source `outputs' tuple $t$. Potentially differing information from multiple sources needs to be reconciled in order to populate a knowledge base. Data sources are not fully reliable; they may output false statements, or not output true statements. Each source has a `false positive' rate, which is the probability that any particular false tuple (from a given set of candidate tuples) is outputted from the source, and a `false negative' rate, the probability that any particular true tuple is not outputted by the source. This creates the need to evaluate the accuracy of these sources, and to take the accuracy into account when determining which tuples to enter into our knowledge base. We consider the following problem:

\stitle{Problem (Informal):} 
\begin{problem}\label{prob:high-level}
Given a set of sources, a set of tuples outputted by each source, with some of the tuples labeled as true or false, estimate the truth probability of each unlabeled tuple, and the false positive and false negative rates of each source.
\end{problem}
In addition to the sources, their tuples, and labels, we will also assume we are given some additional prior information, which we will describe in the detailed problem setting in Section~\ref{sec:formal}.
We call this problem the `{\em Web Source Quality}' problem. There are many dimensions to this problem, based on what assumptions we make. We will list some of these dimensions, and describe existing work in terms of these dimensions. 
\squishlist
\item {\bf Primary Key Existence}: Sometimes, the information to be added to a knowledge base can be thought of as an answer to a discrete question like `Who is the president of the United States?'. In this case, the knowledge base will have a `Presidents' table with the schema (Country, President), and there will be an entry with value `United States' in the first column, and a blank value (to be filled) in the second. In this case, there is only one correct answer associated with each entry in the table (Country is a primary Key). This is known as the `Single Truth Assumption'. In contrast, if we have a table with schema (Book, Author), each book can have multiple `correct' authors associated with it. The Book-Author table has no primary key, and thus the Single Truth Assumption is not valid on this table.
\item {\bf Source Error Model:} Each source has some probability of getting a tuple wrong. Different papers make different assumptions about how sources make errors. Some works assume that sources make errors {\em independently} of each other e.g. If source $A$ has a $0.2$ probability of being wrong about any tuple, and source $B$ has probability $0.3$, then the probability of both sources being wrong on a tuple is $0.2 \times 0.3 = 0.06$. This independence assumption is not usually accurate, as sources often have common sources of errors, such as the inherent `confusingness' of a tuple, or copying data from one another. In addition, some works assume that sources have equal false positive and false negative error rates, or that multiple sources have the same error rate. 

Another aspect of the error model dimension is that of extraction errors: Suppose we have a textual data source, and run an extractor on it and get an incorrect tuple, the tuple could have been incorrect for two reasons; because the source contained incorrect information, or because the extractor did not work correctly and detected spurious information not implied by the source. Thus the total error rate we observe is a combination of two error rates, namely the source error rate, and the extractor error rate. If we treat each source-extractor pair as a single data source, that creates a correlation between the errors of such pairs that have a source value or extractor value in common. 
\squishend

We now describe existing work in this area. All related works by Luna Dong et al~\cite{DBLP:journals/corr/DongGMDHLSZ15,6228170,Pochampally:2014:FDC:2588555.2593674,Dong:2012:LMS:2448936.2448938,Dong:2014:DFK:2732951.2732962} dealing with some form of source quality evaluation or data fusion, make the Single Truth Assumption i.e. They assume there is a set of `questions' to be answered, and each question has only one correct answer, and then attempt to choose which of the many answers obtained from different sources is the correct one. The most recent work~\cite{DBLP:journals/corr/DongGMDHLSZ15} is the only one that takes source errors as well as extractor errors into account, but does not allow for any correlations between the source errors themselves. It has the interesting feature of allowing multiple levels of granularity when defining sources (so each paper could be interpreted as a source, or the entire issue of the journal can be taken to be the source) based on amount of training data needed per source. Reference~\cite{Dong:2014:DFK:2732951.2732962} use variants of the majority heuristic to guess correct answers, and find source error rates using that, while~\cite{Dong:2012:LMS:2448936.2448938} shows that when using a simple technique like majority, sticking to a small number of highly accurate sources can be better than adding more lower quality sources. The above papers assume independence of source errors. There is one work~\cite{Pochampally:2014:FDC:2588555.2593674} which uses gold standard training data to figure out source error rates as well as all multi-way correlations between source errors (which takes exponential time), and has heuristics for approximating the correlations in linear time. Finally, reference~\cite{6228170} is about detecting copying among web sources using some assumptions about copying, which iteratively guesses correct answers to questions, accuracies of sources, and instances of copying between sources. 

Reference~\cite{Qi:2013:MCI:2488388.2488479} again uses the Single Truth Assumption, but allows for correlations between source errors. These correlations are represented in form of `groups' of sources, where errors from sources in the same group are correlated. They learn the groups as well as the number of groups starting with a uniform prior for each group, but they make the strong assumption that each source belongs to exactly one group. Thus in their model, if source $A$ and $B$ are correlated, then sources $A$ and $C$ cannot be correlated unless $B$ and $C$ are also correlated to the exact same degree. This prevents us from having multiple potentially overlapping sources of correlations between groups. In addition, the group structure is fully learned, with no scope for taking prior information from experts into account. For instance, we may expect papers having the same authors to make correlated errors, but there is no way to incorporate this information into the model. Reference~\cite{Zhao:2012:BAD:2168651.2168656} is the only one that does not make the Single Truth Assumption. But it assumes that source errors are independent, and also makes some restrictive assumptions about how to interpret a source {\em not} outputting a tuple.

Thus the main challenge in the Web Source Quality problem is to model correlations between sources in a sufficiently general but tractable way, while taking prior information into account, and without making assumptions about the existence of primary keys for our database table. We address these challenges by creating a generative model that allows experts to specify `groups' of sources that are likely to have correlated errors, and models the way errors are propogated from groups to individual sources. We now describe our framework, and then justify our design choices. 

\subsection{Problem Setting}\label{sec:formal}
Our database consists of a single table $Z$, which we want to populate. We also imagine there is a conceptual table $Z'$ that is fully populated. For instance, $Z$ may be a table with schema, (Country, President), and only a few tuples filled in. Then $Z'$ is a table that contains all countries and their presidents. We say a tuple $t$ is `correct' if it is contained in $Z'$. We now describe notation for the observed data, and our generative model.

We have a given set of data sources $s_1, s_2, ... s_m$. A source can be an online table, a document, or a webpage. We run extractors on every source to get candidate tuples. A candidate tuple is a tuple which we consider as being likely to be correct, though we are not sure of its correctness. We extract several candidate tuples for $Z$ from each of these sources, with each tuple possibly coming from multiple sources. Let $t_1, t_2, ... t_n$ be the candidate tuples extracted. We say source $s_i$ `output' tuple $t_j$ if $t_j$ was obtained by running an extractor on $s_i$. We also say a source $s_i$ is correct on a tuple $t_j$ if either $t_j$ is correct and $s_i$ outputs it, or if $t_j$ is incorrect and $s_i$ does not output it. We define the boolean variable $b_{i,j}$ to be true if tuple $t_j$ was outputted by source $s_i$. In addition, we let $N$ denote the total number of potential tuples, including both correct and incorrect tuples, and tuples that have and haven't been output by any source. Thus $N-n$ tuples will not have been output by any source. We assume that $N$ is given to us.

Each source has a false positive rate and a false negative rate, and our estimates of these rates are also random variables. In addition, sources are not independent. For example, two webpages (sources) on the same website are likely to have several incorrect tuples in common. Thus even if the two webpages are individually correct on $0.8$ fraction of the tuples, the probability of both webpages being correct on any individual tuple may be more than $0.8 \times 0.8 = 0.64$, because of the positive correlation between the webpages' errors. Modelling arbitrary correlation between sources can be expensive, as the number of parameters required for $m$ sources is exponential in $m$. Thus we choose a route between the two extremes of assuming independence of all sources, and allowing arbitrary correlations in sets of sources. We assume that we are given a list of sources-groups $g_1, g_2, ...$, where each group $g$ is a set of sources that are known to be related to each other. For instance, there may be a $g$ for each website, that contains all pages on that website. Or there may be a $g$ for each author, consisting of all papers written by that author. Or we can run copy detection algorithms to find sources that seemed to have copied data from each other, and put those sources into one group. We can have one group that contains all sources, to account for wrong tuples that all sources have a good chance of containing (like the tuple (USA, Bush) for a `Current Presidents' table).

We now define the `error rate' parameters of our generative model. We will describe the effect of these parameters later. For each $g_k$, we have a false positive and false negative rate, given by two random variables $G_{k+},G_{k-} \in [0,1]$ respectively, that represents the `shared' part of the accuracy of sources belonging to $g_k$. We let $G_k$ denote the left stochastic matrix with columns $[1-G_{k-},G_{k-}]^T$, $[G_{k+},1-G_{k+}]^T$. For each source $s_i$, we similarly have two random variables $S_{i+},S_{i-} \in [0,1]$ that denote the `individual' component of its false positive and false negative rate (individual meaning in addition to the $G_k$ parts). We can define matrix $S_i$ analogously to $G_k$. 

As an example of the difference between $G_k$ and $S_i$, if a set of papers was written by the same author, the $G_k$ of the author denotes our estimate of the accuracy of the author's knowledge ($G_{k-}$ is the estimated probability of the author missing a correct tuple, and $G_{k+}$ is that of the author believing in the truth of an incorrect tuple), while the $S_i$ for a document written by the author denotes the estimated probability with which the documents correctly reflect the author's knowledge ($S_{i-}$ is the estimated probability of the document missing a tuple the author believes in, and $S_{i+}$ that of the document containing a tuple the author doesn't believe in). We assume that the error rates of groups and sources ($G_{k-}, G_{k+}, S_{i-}, S_{i+}$ for each $k$ and $i$) are generated (by the generative model) using a beta prior distribution. A beta distribution is specified using two integer parameters. TWe (or domain experts) choose the parameters for the beta distribution so as to have a low value for false positive rates $G_{k+}, S_{i+}$ and a moderate value for the false negative rate. We want the prior to reflect our knowledge that false positive probabilities are generally extremely low (because the number of false tuples is very high, and a randomly chosen incorrect tuple is unlikely to appear in any source) while the false negative probabilities are higher (a randomly chosen correct tuple is likely to not appear in several sources). The exact values for the parameters depend on the total number of tuples, the number of tuples outputted by each source, and so on. (NOTE: Add more on this later)

We now describe the actual generative model. For an example of a simpler model, see Section~\ref{sec:causal-model-example}. Consider any tuple $t_j$. We use the random variable $T_{+} \in [0,1]$ to denote the prior probability of any $t_j$ being correct (prior meaning prior to looking at any source outputs). Let $T$ be the left stochastic matrix $[T_{+},1-T_{+}]^T$. Each $t_j$ has one boolean random variable $T_j$ that says whether $t_j$ is correct or not. $T_j$ can take two values which are both column matrices: $[1,0]^T$ which stands for `true', and $[0,1]^T$ which stands for `false'. Thus $P(T_j) = T_{j}^{T}T$ before conditioning on any other information. Now for each source group $g_k$, the probability that $g_k$ `believes' in tuple $t_j$ is given by the matrix product $[1,0]G_kT_j$. We use the boolean random variable $T_{j,k}$ to denote whether or not $g_k$ believes in $t_j$ (which again takes value $[1,0]^T$ standing for `true', or $[0,1]^T$ standing for `false'). For any source $s_i$, group $g_k$ containing $s_i$, and any tuple $t_j$, the probability that $s_i$ `believes' in $t_j$ via group $g_k$ is given by $[1,0]S_iT_{j,k}$. We use the boolean random variable $T_{j,k,i}$ to denote whether or not $s_i$ believes in $t_j$ via $g_k$. Finally, we wish to assume that each source $s_i$ outputs a tuple $t_j$ is and only if its believes in $t_j$ via some group containing $t_j$. That is, if and only if $\lor_{k : s_i \in g_k} T_{j,k,i}$. But we instead assume that there is a fixed small $\epsilon$ such that a source outputs a tuples with $\epsilon$ probability if $\lor_{k : s_i \in g_k} T_{j,k,i}$ is false, and fails to output the tuple with $\epsilon$ probability if $\lor_{k : s_i \in g_k} T_{j,k,i}$ is true. The reason for not setting $\epsilon = 0$ is to make Gibb's sampling possible when solving the problem. We only get to observe whether a source outputs a tuple or not, and need to use that to deduce the values of other latent variables. 

In addition to knowing which tuples were outputted, we may have knowledge about relations between certain tuples. For instance, a source may contain a line of text that can be interpreted as $(a,b)$ or $(a, b')$, but not both. In that case, we want a way to represent the fact that the probabilities of the tuples $(a, b)$ and $(a, b')$ being correct are negatively correlated. Or, we may know that say $A$ is a primary key for a table with columns $A,B$. Then two tuples $(a,b)$ and $(a,b')$ are incompatible, and again their probabilities are negatively correlated. In order to represent this fact, we create a set of tuple-groups $h_1, h_2, ..$ such that of all the tuples from any group, only one is correct, with high probability (the reason behind assuming high probability rather than probability $1$ is again to make Gibb's sampling possible). We assume that the probability penalty for each pair of conflicting tuples (belonging to a common tuple-group) being correct is some small constant $\epsilon$ per common tuple-group. (NOTE: We can probably allow arbitrary constraints between tuples, not just the exclusiveness constraints.)

Let $P_J$ denote the un-normalized joint probability distribution over all random variables. For any source $s_i$, let $g(s_i)$ denote the set of indices of source groups that contain $s_i$. 
Using $\overrightarrow{T}$ to denote the vector of random variables $T_1..T_n$, $\overrightarrow{S}$ for $S_1..S_m$, $\overrightarrow{G}$ for $G_1, ... G_k$,  $\overrightarrow{T_G}$ for $T_{1, 1}, ..$, $\overrightarrow{T_S}$ for $T_{1, 1, i_1}, ..$, $P$ is given by:

\begin{align}\label{eq:joint-prob} 
& P_J(\overrightarrow{T}, \overrightarrow{T_S}, \overrightarrow{T_G}, T, \overrightarrow{S}, \overrightarrow{G}) =
\\& P(N) \times P(T) \times (\prod_{k} P(G_k)) (\prod_{i} P(S_i)) \times
\\& (\prod_{j=1}^{N} T_{j}^{T}T \prod_{k} T_{j, k}^{T}G_kT_j \prod_{i:s_i\in g_k} T_{j,k,i}^{T}S_iT_{j,k}) \times 
\\& (\prod_{j} \prod_{i} \epsilon^{I(b_{i,j} \neq \lor_{k : s_i \in g_k} T_{j,k,i})})
\\& (\prod_{l} \prod_{1 \leq j_1 < j_2 \leq n} \epsilon^{I(T_{j_1} \land T_{j_2} \land (t_{j_1}\in H_l) \land (t_{j_2} \in H_l)}))
\end{align}
where $I$ is an indicator function, and $P(N), P(T), P(G_k), P(S_i)$ are the prior probabilities. The first line in the above formula for probability is the product of prior probability densities for the number of tuples, for a tuple being correct and the false positive and negative rates of all sources and groups. The second line the the probability of the $T_j, T_{j,k} T_{j,k,i}$ variables in terms of the false positive and negative rates. The third line imposes the condition that a source $s_i$ outputs a tuple $t_j$ if and only if its $T_{j,k,i}$ is true for at least one $k$, with an $\epsilon$ probability of this being violated for each source tuple pair. The fourth line creates an $\epsilon$ probability penalty every time a pair of incompatible tuple variables from a tuple-group have both been set to true.

\subsubsection{An Example}\label{sec:causal-model-example}
We now give an example of a simplified version of our model. We assume there is a single source $s_1$, and that there are no groups. There is a set of `possible' tuples, which consist of the domain of $Z$, and for each tuple, the universe assigns a value of `correct' to it with probability $T_{+}=0.1$. So if there are a million possible tuples, the universe will make approximately $10^5$ of them correct, and the others incorrect. Now suppose the source has a false negative rate of $S_{1+} = 0.8$, and a false positive rate of $S_{1-} = 0.01$. That is, for each correct tuple, the source has a probability $S_{1+} = 0.8$ of `disbelieving' in it, and $0.2$ of `believing' in it to be correct. In this case, each source is going to output exactly those tuples that it believes in. Overall, the source will believe in around $20000$ correct tuples. For each incorrect tuple, the source has $0.01$ probability of believing in it, and $0.99$ of disbelieving in it. So it will believe in around $9000$ incorrect tuples. The source will thus output around $29000$ tuples, of which around $20000$ will be correct. When we are solving Problem~\ref{prob:high-level} for this set of sources and outputs, we wil not know in advance which tuples are correct, (except for the ones that are part of the training data). In general, we will not know the parameters $T$, $S_{1+}$, $S_{1-}$ or the number of total tuples, in advance. We will have the guess the values of the parameters using the observed data and our training data. If there are multiple sources, then tuples output by more than one source will be more likely to be correct, which will also help us guess which tuples are correct, and what the source false positive and negative rates are.

\subsection{Justification of our problem setting}
We use the idea of groups to model correlations between sources. This allows us to model multiple overlapping causes of correlations between sources. For instance, we can have one group containing papers written by the same author, one group for papers that talk about the same entity, one group for webpages from the same domain, and so on. We can run copy detection algorithms to find sources that have copied data from each other, and put them in a group. One source can belong to multiple groups, and thus share different kinds of errors with different sources, and have correlations of differing strength with different sources, in contrast to the disjoint group model in reference~\cite{Qi:2013:MCI:2488388.2488479}. The group structure is flexible, allowing us to trade off computation time for accuracy. For instance, by having only one group with $0$ false positive and false negative rate (set using the priors), we can effectively simulate a model where sources are independent. Adding more groups increases the accuracy of the model, but increases computation and memory costs, and can cause overfitting. 

Having groups specified beforehand allows us to incorporate our prior knowledge about relations between source errors. For instance, a domain expert can tell us which sources tend to agree with each other, and we can create groups to reflect that in our model. Groups created this way are also interpretable, and the error rates found for these groups can be connected to corresponding real world entities, such as journals or websites. One weakness of our model is that groups aren't learned; we can potentially compensate for this by running the model with multiple groupings and seeing which group structure works best. 

We do not make the single truth assumption, to increase the applicability of our work. If we need to populate a table which does not have a primary key, then we need a model that doesn't make the single truth assumption. For instance, we have a table with schema (gene, phenotype), and we wish to populate it with information on which genes are associated with which phenotypes. Since a single gene can be associated with multiple phenotypes, we need to avoid making the single truth assumption. Another such example is a book-authors table, where each tuple has a single book-author pair, but one book can have multiple authors. In fact, our setting is even more general than the one in~\cite{Zhao:2012:BAD:2168651.2168656}, which doesn't have the single truth assumption, but still assumes that each tuple consists of an `entity' and a claim about that entity. 
On the other hand, if we do have a table with a primary key, we can enforce the single truth assumption there by using the tuple-groups in our model. With minor modifications to our model, we can also simulate the setting in~\cite{Zhao:2012:BAD:2168651.2168656}, by choosing one group per entity, and connecting it to all sources that output at least one tuple about that entity and initializing the group to believe in all tuples that talk about that entity. 

A knowledge base usually consists of multiple tables, with different primary key constraints within some tables, and foreign key constraints between several tables.
There can be other probabilistic constraints on tuples in the knowledge base. We choose our setting so that tuples outputted by sources can potentially belong to different tables, with different kinds of constraints within or between tables (modelled using tuple-groups). Moreover, as stated before, our setting is general enough to be able to model the single truth assumption when necessary, or an assumption similar to the one in~\cite{Zhao:2012:BAD:2168651.2168656}, but can also apply to settings not covered by previous work. We do not currently consider extractor errors separately from source errors; we can work around this by treaating each source-extractor pair as a `source'. and each source as a `group'. 

Hence to summarize, our setting is very general, and capable of incorporating prior knowledge, and can be tailored to a wide variety of realistic scenarios. 

\section{Solution Sketch, Collapsed Gibb's Sampling}
% We have a set of variables with a joint probability distribution. we can sample from the distribution using gibbs sampling. describe gibbs. then describe collaposed gibbs with simple example of bernoulli's+beta. Then describe how it applies to our thing. with counters and stuff.  

\subsection{An overview of Gibb's Sampling}
Suppose we have $n$ variables $A_1, A_2, ... A_n$, and we want to obtain samples from this distribution. Let the vector $\overrightarrow{A}$ denote an assignment to each of the $A_i$s. There is a joint probability distribution $P(\overrightarrow{A})$ over them. Computing the value of this distribution exactly, at arbitrary values of $\overrightarrow{A}$, can be NP-Hard. However, computing an un-normalized version of the probability (or equivalently, the ratio between the probabilities of two different $\overrightarrow{A}$s) can be feasible. By un-normalized version, we mean a multiple of the actual probability (so the un-normalized probabilities over all different $\overrightarrow{A}$s may not add up to one). Our joint probability distribution in Equation~\ref{eq:joint-prob} is an example. The equation gives the un-normalized probability of an assignment to the variables, which can be computed in linear time. But computing the actual probability would require computing the normalizing constant, which is hard. If we want the ratio of probabilities of two assignments, the normalizing constants would cancel out, and we could simple compute the ratio by dividing the un-normalized probabilities using Equation~\ref{eq:joint-prob}. In such a situation, Gibb's sampling can be used to obtain samples from the distribution, as shown in algorithm~\ref{alg:gibbs}. The user specifies the number of required samples $k$, the un-normalized probability distribution function $P$, the set of variables $\overrightarrow{A}$, and two large integer parameters, $burnIn$, and $thinFactor$. These two parameters determine how long the sampling takes, and how close the sampling probabilities are to the actual probabilities. As $burnIn, thinFactor \rightarrow \infty$, the sampling probabilities of the Gibb's sampling algorithm tend to actual probabilities we want to sample.

The algorithm itself is simple. We iterate over the variables one by one, and `change' the value of the variable based on its probability distribution keeping all other variables fixed. We do this for all variables, several times, and save the resulting values to get a sample once every $thinFactor$ times. In the example shown, the domains of all variables are assumed to be discrete (since we are iterating over $v \in \text{Daomin}(A_i)$, but this can be made for work for continuous variables in a similar way. 
In case of our probability distribution in Equation~\ref{eq:joint-prob}, we have some continuous variables (the false positive, false negative rates, and so on) and some  boolean variables (the truth values and beliefs). We can run Gibb's sampling over those values to sample from our distribution, and the samples can be used to estimate the probability of a tuple being true, the probability of a group believing a true tuple, and so on. 

\begin{algorithm}\label{alg:gibbs}
\scriptsize
\KwIn{$k$ (Number of samples required), $P$ (un-normalized probability function), $\overrightarrow{A}$ (variables), $burnIn$, $thinFactor$}
\KwOut{$S$ (Solution set of rules)}
$S = \phi$ \tcc*{Initialize multi-set of samples}

$\overrightarrow{A} = (0,0,0,...0)$ \tcc*{Initialize arbitrarily, in this case to all $0$s.}

$n = \text{length}(\overrightarrow{A})$

\For {$iter$ from $1$ to $burnIn + (k-1) \times thinFactor$}{
  \For{$i$ from $1$ to $n$}{
    $\textrm{ProbTotal} = 0$

    $\textrm{Probs} = []$ \tcc*{Array of un-normalized probabilities}

    \ForEach{$v \in \text{Domain}(A_i)$}{
      $\overrightarrow{A}(i) = v$

      $\textrm{Probs}[v] = P(\overrightarrow{A})$

      $\textrm{ProbTotal} += P(\overrightarrow{A})$
    }

    Sample $v \in \text{Domain}(A_i)$ with probability $\frac{\textrm{Probs}[v]}{\textrm{ProbTotal}}$

    $\overrightarrow{A}(i) = v$
  }

  \If{$iter \geq burnIn \And iter \% thinFactor == 0$}{
    $S = S \cup \left\lbrace \overrightarrow{A} \right\rbrace$
  }
}
\Return $S$
\caption{Gibb's Sampling}
\end{algorithm}

\subsection{Collapsed Gibb's sampling}
Suppose we have a set of variables $B, A_1, A_2, ... A_n$, where the $A_i$'s are boolean variables, while $B$ is a real number variable in $[0,1]$. Again let $\overrightarrow{A}$ denote an assignment to all $A_i$s. Suppose the probability distribution is given by $P(B, \overrightarrow{A}) = \Pi_{i=1}^{n} (A_iB + (1-A_i)(1-B))$. That is, $B$ is chosen uniformly, and then each $A_i$ is chosen to be $1$ with probability $B$ independently of all other $A$s. Let $C_{+}(\overrightarrow{A})$ be the number of $A_i$s that are true, and $C_{-}(\overrightarrow{A})$ be the number of false values. Then the joint probability is also given by $B^{C_{+}(\overrightarrow{A})}(1-B)^{C_{-}(\overrightarrow{A})}$. We could do Gibb's sampling on this by sampling variables $A_i$ with probability $B$ of being $1$, and then sampling $B$ with probability equal to $\frac{B^{C_{+}(\overrightarrow{A})}(1-B)^{C_{-}(\overrightarrow{A})}}{\beta(C_{+}(\overrightarrow{A_{-i}}), C_{-}(\overrightarrow{A_{-i}}))}$, where the $\beta$ is the normalization constant. But we can also speed up the process by integrating out $B$, and only sampling from the distribution over $\overrightarrow{A}$. The $A_i$s are independent when $B$ is fixed, but when we integrate out $B$, they becomes positively correlated with each other. If $\overrightarrow{A_{-i}}$ represents the assignment of values of all variables other than $A_i$, then we can show that the probability of $A_i$ when other variables are fixed is given by:
\begin{align*}
&P(A_i \mid \overrightarrow{A_{-i}})\\
= &\int_{b=0}^{1} P(A_i \mid \overrightarrow{A_{-i}}, B=b) P(B=b \mid \overrightarrow{A_{-i}}) db\\
= &\int_{b=0}^{1} b \times \frac{b^{C_{+}(\overrightarrow{A_{-i}})}(1-b)^{C_{-}(\overrightarrow{A_{-i}})}}{\beta(C_{+}(\overrightarrow{A_{-i}}), C_{-}(\overrightarrow{A_{-i}}))} db\\
= &\frac{1 + C_{+}(\overrightarrow{A_{-i}})}{2 +  C_{+}(\overrightarrow{A_{-i}}) +  C_{-}(\overrightarrow{A_{-i}})}
\end{align*}
We can use this to iteratively change each $A_i$ based on values of other $A$s (while continuously maintaining a counter for $C_{+}(\overrightarrow{A})$ which gives us the conditional $A_i$ probabilities), and this will give us samples for $\overrightarrow{A}$ from our probability distribution. The samples can then also be used to get a probability distribution for $B$. This is an example of Collapsed Gibb's sampling. We can apply that to our probability distribution in Equation~\ref{eq:joint-prob}, as we show next.

\subsection{Our (current) solution}
We maintain counters $t_{+}, t_{-}$ of the number of `true' and `false' tuples at all points. For each group $g_k$, we maintain four counters, $g_{k++}, g_{k+-}, g_{k-+}, g_{k--}$. $g_{k++}$ is the number of true tuples that $g_k$ believes in, $g_{k+-}$ is the number of false tuples that $g_k$ believes in, and so on. Similarly, for each source $s_i$, we maintain $s_{i++}, s_{i+-}, s_{i-+}, s_{i--}$. We have a beta prior over the false positive and negative probabilities of each group and source, which are expressed by adding appropriate constant values to each of the counters (so the counters include not only the number of actual true/false tuples/beliefs, but also the initialization values). Then, in each iteration, we go over each boolean variable one by one, and reassign it a value with a conditional probability based on other variable's values. Specifically, for each tuple $t_j$, let 
$$P_{j+} = \frac{t_{+}}{t_{+}+t_{-}}\Pi_{k}\left[ \frac{g_{k++}}{g_{k-+} + g_{k++}} \frac{g_{k-+}}{g_{k-+} + g_{k++}}  \right] T_{j, k}$$ 
and let 
$$P_{j-} = \frac{t_{-}}{t_{+}+t_{-}}\Pi_{k}\left[ \frac{g_{k+-}}{g_{k+-} + g_{k--}} \frac{g_{k--}}{g_{k+-} + g_{k--}}  \right] T_{j, k}$$ 
NOTE: We are currently ignoring the terms for mutually exclusive tuples. But that's easy to add here. Actually, there's no reason to just have mutually exclusive tuples, since the argument for collapsed doesnt need it. We can allow an arbitrary factor graph on tuples. 

Then the probability that we set $T_j$ to true is given by $\frac{P_{j+}}{P_{j+}+P_{j-}}$. If we do change the value of $T_j$ in that step, we also need to update counters $t_{+}, t_{-}$ and all the $g$ counters. For instance, if $T_j$ was changed from false to true, then $t_{j+}$ would go up by $1$, $t_{j-}$ down by $1$, $g_{k++}$ would go up for $k$'s such that $T_{j,k}$ was true, $g_{k+-}$ would go down where $T_{j,k}$ was true, and so on. 

Similarly, when deciding if to change $T_{j,k}$, we have
$$P_{j,k+} = [g_{k++} g_{k+-}] T_j \Pi_{i}\left[ \frac{s_{i++}}{s_{i-+} + s_{i++}} \frac{s_{i-+}}{s_{i-+} + s_{i++}}  \right] T_{j, k, i}$$ 
$$P_{j,k-} = [g_{k-+} g_{k--}] T_j \Pi_{i}\left[ \frac{s_{i+-}}{s_{i+-} + s_{i--}} \frac{s_{i--}}{s_{i+-} + s_{i--}}  \right] T_{j, k, i}$$ 
and the probability of setting $T_{j,k}$ to true is given by $\frac{P_{j,k+}}{P_{j,k+} + P_{j,k-}}$. If $T_{j,k}$ is changed, we will have to change counters for $g_{k++}, g_{k+-}, ..$ and for all $s_i$'s where source $s_i$ belongs to group $g_k$.

Finally, changing $T_{j,k,i}$ is similar. In addition to the $[s_{i++} s_{i+-}] T_{j,k}$ term, it will have a term that connects the `Or' of the $T_{j,k,i}$s to output $b_{i,j}$. 

An implementation of the solution given above works on simulated data with $\approx 20000$ tuples, $4$ groups and $10$ sources. It finds the source accuracies reasonably well, but it takes a long time $\approx$ 25 minutes. Since the number of sources in real datasets are much higher, this means the implementation will not finish in a reasonable amount of time on our real datasets. 

\subsection{Efficiency and Sparsity} 
The number of boolean variables in our model can be very large, for real datasets. Firstly, we assume that there is a large number of false tuples that are never outputted, which increases the number of tuple variables (relative to the number of tuples that have actually been outputted). In addition, for each $i, j, k$ such that source $s_i$ is in group $g_k$, we have one boolean variable $T_{j,k,i}$. This means the number of variables is at least equal to the number of tuples times the number of sources. For a data with $800$ sources and $10000$ outputted tuples (which are the sizes for one of our real datasets), the number of variables is at least $8$ million, which is very large. Each iteration of the collapsed Gibb's sampling involves making a pass over $8$ million tuples, and we need a large number of such passes to generate samples. Moreover, each step of changing the value of a random variable involves several multiplications (to compute the conditional probability of the variable taking value true or false), and several updates to the counters in case the value is changed. 

We compute the conditional probability even for variables which are almost guaranteed to be false (e.g. $T_{j,k,i}$ where $t_j$ was not outputted by $s_i$, $T_j$ where $t_j$ was never outputted). Although the number of sources and tuples is large, we have two factors that need to be used to speed up our sampling:
\squishlist
\item A large number of tuples are false and never outputted
\item Even for tuples that have been outputted, they are usually outputted by only a small fraction of the sources. That is, the source-tuple graph is sparse.
\squishend

We can try using these factors by making the following changes:
\squishlist
\item Instead of instantiating boolean variables for all $T_{j}, T_{j,k}, T_{j,k,i}$s, we will only instantiate $T_j$'s where $t_j$ has been outputted at least once, $T_{j,k}$ where $t_j$ has been outputte dbe at least once source belonging to group $g_k$, and $T_{j,k,i}$ where source $s_i$ belongs to group $g_k$ and has outputted tuple $t_j$. The others are assumed to be permanently false (but they will still be counted in their corresponding counters, as they still affect our error rate estimates for sources and groups.)
\item We don't need to explicitly maintain $g_{k-+}, g_{k--}$ for any $k$. They can be computed on the fly using $g_{k-+} = t_{+} - g_{k++} + <prior terms>$, $g_{k--} = t_{-} - g_{+-} + <prior terms>$ (By $<prior terms>$ we mean the parts of the counters that were set to specify the prior probabilities of $g_k$'s error rates). Since we are only maintaining $g_{k+-}, g_{k++}$, when a $T_j$ changes, we only need to update the counter for groups that believe in $T_j$ i.e. for groups where $T_{j,k}$ is true. Since most groups won't believe in most tuples (due to sparsity of the source-tuple relation), this will save a lot of time. This would still be problematic if there is a large number of groups connected to a large number of sources.
\item When deciding if to change $T_j$, we need to compute a likelihood estimate for all groups $g_k$ based on the current value of $T_{j,k}$ and the counters for the group. If $T_{j,k}$ is true, the odds ratio $\frac{P_{j+}}{P_{j-}}$ that we have to compute would be multiplied by $\frac{g_{k++}t_{-}}{g_{k+-}t_{+}}$, and if $T_{j,k}$ is false, it would be multiplied by $\frac{g_{-+}t_{-}}{g_{k--}t_{+}}$. The latter of these quantities is very close to $1$ for groups that are only connected to a few sources (since for those groups we will have, $g_{k-+} \approx t_{+}, g_{k--} \approx t_{-}$), so we can probably just ignore those terms while calculating odds. This will reduce time for calculating odds while deciding if to change $T_j$.
\item The two points above were on changing $T_j$, for reducing number of updates, and reducing cost of computing odds respectively. We need to make similar improvements to the process of changing $T_{j,k}$. Both the updates and the odds computation take time proprtional to the number of sources belonging to group $g_k$. If we assumed that all groups were small, then this would run fast. If a group is large (say there is a group that contains all sources), then we would like to extend the above ideas to try and update only $s_{i++}..$ values such that $T_{j,k,i}$ is already true, and to skip the odds computation for sources where $T_{j,k,i}$ is false. Unfortunately, earlier ideas do not directly extend to this setting, because unlike $g_{k--}$, $s_{i--}$ cannot directly be computed in terms of $s_{i+-}$ (so we would need to maintain this counter and update it even when $T_{j,k,i}$ is false). The odds computation is harder as well, because the odds multiplication term when $T_{j,k,i}$ is false is $\frac{s_{i-+}(s_{i+-} + s_{i--})}{s_{i--}(s_{i-+}+s_{i++})}$, and its not clear if this is bound to be close to $1$. 
\squishend

Some other ideas for making computation faster, by potentially changing the model, are:
\squishlist
\item Assume that all groups are connected to only a small number of sources. (This assumption makes it hard to explain data when there are false tuples that are outputted by a large number of sources, like the (USA, Bush) tuple).
\item Currently, if a source does not output a tuple, we are treating it as asserting that the tuple is false (and making it count towards the false negative rate). We would allow a model where model source-tuple or group-tuple relations are labelled `ignore' rather than false. That way, when computing odds, we do not need to do the odds mutliplication for the `ignore' edges.
\item We can make a source have an indepedent error rate for each group it belongs to (so a source is connected to each group with a different strength). This might make the odds computation easier, because a source $s_i$'s error rate wrt a group $g_k$ depends only on $T_{j,k,i}$s, and we can possibly approximately it using the count of $g_k$ beliefs and disbeliefs (similar to what we do when updating a $T_j$).
\item For things which get updated infrequently, does it make sense to skip some update. For example, if a variable has a $]frac{1}{10000}$ chance of getting flipped, then is it ok to skip it for $100$ iterations and then flip it with probability $\frac{1}{100}$? Other tricks for optimizing Gibb's sampling, including better initialization of values, may allow us to sample for fewer iterations, and thus reduce computation time.     
\squishend

% model changes/ open world assumption/small groups assumption. 
% gibbs optimizations.





\begin{comment}
\section{Solution Sketch (Old)}
Our problem involves two kinds of variables we need to estimate: (i) Boolean variables (with column matrices corresponding to `true' and `false' values), such as $T_j$, $T_{j,k}$ and $T_{j,k,i}$ (ii) Real number variables, which are the baseline correctness probability $T$, and false positive and false negative rates of sources or source-groups. For the boolean variables, we want to find the \textit{marginal probability} of them being correct, which is itself a real number. 

Given a some training data (a set of correct and incorrect tuples for the table), we can solve this problem in a way similar to Deepdive~\cite{deepdive,Niu_deepdive:web-scale}. First, we explain some terms needed for the solution. Our joint probability distribution over the boolean variables as a \textit{factor graph}. A factor graph is a bipartite graph, with two types of nodes, \textit{variables} and \textit{factors}. On one side of the bipartite graph are variable nodes, each of which corresponds to a random variable whose value we wish to infer. In our case, we create a variable node for each of our boolean random variables ($T_j, T_{j, k}, T_{j,k,i} ..$). A \textit{possible world} refers to an assignment to all the variable nodes in the graph. The other side of the bipartite graph has factor nodes. Each factor node is connected to one or more variable nodes, and represents a relation between their probabilities. For instance, if two tuples $T_{j_1}, T_{j_2}$ are mutually incompatible because of say, a primary key constraint, then we will construct a factor node that is connected to $T_{j_1}$ and $T_{j_2}$ to represent their negative correlation. Each factor node is associated with a boolean \textit{expression} involving the variable nodes connected to it, and a \textit{weight}. To continue the example above, say we have mutually incompatible tuples $T_{j_1}, T_{j_2}$, and a factor node $f$ connected to both of them. Then $f$ will be associated with the expression $T_{j_1} \land T_{j_2}$, and a large negative weight $w_f$. The interpretation of this is that in any possible world where the expression of $f$ evaluates to true, the probability of the resulting world is multiplied by $e^{w_f}$. In this case, because $w_f$ is a large negative weight, we will heavily penalize any assignment to the variable nodes that makes both $T_{j_1}$ and $T_{j_2}$ true. In general, the un-normalized probability of a possible world is obtained by multiplying the $e^{w_f}$ values for every factor whose expression evaluates to true in that world.

A factor graph thus encodes a probability distribution over the set of possible worlds. Computing the exact marginal probability distribution of any variable in the graph can be computationally infeasible, but we can use Gibb's sampling to approximate the joint probability distribution over possible worlds, and use it to measure the marginal probability distribution over each variable node. If the weights of some factors are not known beforehand (for example, because they depend on an unknown quantity like the false positive rate of a source), we can `learn' these weights using training data. So if we are given a certain set of tuples that are known to be correct and a set of tuples known to be incorrect, we can choose the weights so as to maximise the resulting marginal probability assigned to the correct tuples, and minimize that of the incorrect tuples. 

We will encode our random variables in two forms. Our boolean random variables ($T_j, T_{j,k}, T_{j,k,i}..$) will form variable nodes in the factor graph. The real number random variables ($T, G_k, S_i..$) will be encoded in the weights of certain factors. We can then use training data to figure out the correct weights, and hence the optimal values of the real number random variables. Our prior distribution $P(T), P(G_k), P(S_i)$ over error rates can also be taken into account in the weight learning process. Once weights are learned, we can then use Gibb's sampling to figure out the marginal probability of each tuple being correct, the marginal probability of each source being correct about a particular tuple, and so on. 

For our problem, we set the variable nodes to the boolean random variables in $\overrightarrow{T}, \overrightarrow{T_S}, \overrightarrow{T_G}$. For each tuple-group, for each pair of tuples $t_{j_1}, t_{j_2}$ in it, we create a factor consisting of $T_{j_1}, T_{j_2}$ with the expression $T_{j_1} \land T_{j_2}$, and weight $\logit(\epsilon)$ (where $\logit(p)$ means $\log\frac{p}{1-p}$). For each tuple $t_j$ and source $s_i$, we also create a factor connecting $T_{j,k,i}$ for all groups $g_k$ that contain $s_i$. The expression for this factor is $b_{i,j} \neq \lor_{k} T_{j,k,i}$, and weight is $\logit(\epsilon)$. 

%***IMPORTANT***: Need to put the prior over S and G somewhere. Additional restrictions on weights. 

Now we have the specify the factors and weights that encode the real number random variables. For each group $g_k$, we define four sets of factors, with four corresponding weights. For each tuple $t_j$, we create four factors with the expressions and weights as follows: $[(T_{j,k} \land T_j, w_{g_k++})$, $(T_{j,k} \land \lnot T_j, w_{g_k+-})$, $(\lnot T_{j,k} \land T_j, w_{g_k-+})$, $(\lnot T_{j,k} \land \lnot T_j, w_{g_k--})]$. When the optimal values of these weights are found, we can use them to find $T$ and $G_k$ using the following equations:
$$T_{+} = \frac{\prod_{k} (e^{w_{g_k++}} + e^{w_{g_k-+}})}{\prod_{k} (e^{w_{g_k++}} + e^{w_{g_k-+}}) + \prod_{k} (e^{w_{g_k+-}} + e^{w_{g_k--}})}$$
$$G_{k+} = \frac{e^{w_{g_k+-}}}{e^{w_{g_k+-}} + e^{w_{g_k--}}}$$
$$G_{k-} = \frac{e^{w_{g_k-+}}}{e^{w_{g_k-+}} + e^{w_{g_k++}}}$$

We can encode $S_i$ similarly. For each source $s_i$, we have four sets of factors, each with a corresponding weight. For each tuple $t_j$, and group $g_k$ containing $s_i$, we have factors with the following expressions and weights : $[(T_{j,k,i} \land T_{j,i}, w_{s_i++})$, $(T_{j,k,i} \land \lnot T_{j,i}, w_{s_i+-})$, $(\lnot T_{j,k,i} \land T_{j,i}, w_{s_i-+})$, $(\lnot T_{j,k,i} \land \lnot T_{j,i}, w_{s_i--})]$. The values of $S_i$ can be found using 
$$S_{i+} = \frac{e^{w_{s_i+-}}}{e^{w_{s_i+-}} + e^{w_{s_i--}}}$$
$$S_{i-} = \frac{e^{w_{s_i-+}}}{e^{w_{s_i-+}} + e^{w_{s_i++}}}$$
\end{comment}

%%%%%%%%%
%Given a factor graph, with the graph structure, expressions, and weights specified, we want to find the probability distribution of values for each variable node in the graph. Finding the exact probability distribution is intractable for several graphs, but we can estimate the probability distribution using Gibb's Sampling. That is, we start from a random possible world, and then change the value of variables in it one at a time, in accordance with the total probability distribution. If we do this for sufficiently many iterations, the probability with which we reach a possible world approaches the actual probability of that possible world according to the total probability distribution. Then by counting the fraction of sampled possible worlds in which a variable node $T$ was set to true, we get an estimate of the marginal probability of $T$ being true. 

%For learning weights, we can use some training data, along with stochastic gradient descent. Unlike for most gold-standard based evaluations, we are not using only the training data for evaluating source accuracies. We may have a small amount of training data with a large amount of unlabelled data, and our procedure uses both of these to evaluate sources. 


% xor and product make sense, but resulting logits are not factorizable, into a factor part and a source part. can use mutiplicative logits instead, but doesn't seem to have a good interpretation. or can create factors for each subset of each g, (so the number of factors and parameters is now exponential in the size of g). EDIT: Can sort of factorize, by adding the new hidden boolean variables defined above. Those vars have a solo factor that reflects the accuracies of sources, or source-groups, and there is an additional factor that relates them, via XOR or AND logical expression, to the displayed value (true). 

% Important below, justification of above design choices.
% To model fact that there are many 'false' tuples, so prob(showing|false tuple) is very low, while prob(not showing|true tuple) is not that low. To reflect this, prec/recall don't seem right, as they make no reference to unshown false tuples. So using actual conditional probabilities from previous sentence instead. What if multiple sources show a tuple, doesn't that guarantee that tuple is true due to low value of prob(showing|false)? Not necessarily, because the falseness may have come from the source-group variable (assuming sources showing the tuple belong to a common source-group), and so the low probability is taken only once, not multiple times. <- Actually, taking accuracy alone (based on #false tuple x false neg. rate) doesn't work. Works if one source outputs. But if two sources output a tuple, then in prob. the #false tuples is counted only once (in tuple prior) while false neg rate is counted twice (once per source). Thus the individual components of accuracy (#false tuples, false neg rate) matter. Need to model separately. And of course, false tuples with different false negative rates (US, bush vs US, manas). Actually,the (US,Bush) like tuples get taken care of by groups right? But what if they're output by two sources not in same group due to bad group-finding? Answer: We always have one group that contains all sources. 
% Seems hard to factor the conditional probs such that the factor weights are meaningful, and have equal values for equal things (like prior prob over all tuples should correspond to some shared factor weight). compromise by just having accuracies (instead of false pos/false neg) and only applying it to candidate tuples? So here's what I do. In the background, we have the full model with lots of false tuples, low false positive prob (but reasonable product of false pos. prob and numberof false tuples), higher false neg prob. So we have a low prior on each tuple. We could do the processing on each tuple (displayed and not displayed), and we can count a source not displaying a tuple as negative evidence. But becuase of low prior prob. we can ignore non-displayed tuples (as it takes the low false pos.probability event of a tuple being displayed in order to push it up from its low prior). And because of high false neg. prob (most sources don't get most tuples), we can ignore it when a source doesn't display a tuple. Thus our full scheme, with these approximations, reduces to the practised scheme of only taking displayed tuples, giving them a low prior prob., modifying it with source accuracy which is high (its like 1 - false pos. prob(?)) for sources which display it, and ignoring sources which don't display it. 

% taking only positive tuples still seems worrying. because it always seems on any tuples, all sources are going to be right or all are going to be wrong (if they have common-ish groups). So it seems always better to blame all mistakes on factors).

% new twist by aditya. instead of assuming all groups are given, try to predict groups based on sources making same errors? this may have been done, to some extent.
% Another thing we need to do (not quite a twist). There are correct tuples (US, Obama), wrong tuples (US, Manas), and slightly wrong tuples (US, Bush).


\begin{comment}
Later:
Crowdsourcing with budget
Key constraints (part of tuple correlations?)
partial extraction
partial correctness.
\end{comment}

%\balance
{\small
\bibliographystyle{abbrv}
\bibliography{WebSourceQuality}  
}

\end{document}
