\documentclass{sig-alternate}
\usepackage{graphicx}
\usepackage{balance}  % for  \balance command ON LAST PAGE  (only there!)
\usepackage{enumitem}
\usepackage{times}
\usepackage{subfigure}
\let\proof\relax
\let\endproof\relax
\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx,color}
\usepackage{verbatim}
\usepackage{framed}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{framed}
\usepackage[normalem]{ulem}
\usepackage[export]{adjustbox}


\usepackage[font={small,it}]{caption}

\renewcommand{\baselinestretch}{1.0}

\renewcommand*\ttdefault{cmvtt}
\usepackage[T1]{fontenc}

% \usepackage{floatrow}
% \floatsetup[table]{font=scriptsize}
% \renewcommand\FBbskip{-10pt}


\newtheorem*{theorem*}{Theorem}
\newtheorem{theorem}{Theorem}
\newtheorem*{lemma*}{Lemma}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{example}[definition]{Example}
\newcounter{prob}
\newtheorem{problem}[prob]{Problem}

\newcommand{\agp}[1]{\textcolor{green}{Aditya: #1}}
\newcommand{\mrj}[1]{\textcolor{red}{#1}}
\newcommand{\mrjdel}[1]{\textcolor{red}{\sout{#1}}}

\newcommand{\squishlist}{
   \begin{list}{$\bullet$}
    { \setlength{\itemsep}{0pt}
      \setlength{\parsep}{2pt}
      \setlength{\topsep}{2pt}
      \setlength{\partopsep}{0pt}
    }
}
\newcommand{\stitle}[1]{\vspace{0.5em}\noindent\textbf{#1}}
\newcommand{\squishend}{\end{list}}
\newcommand{\eat}[1]{}
\newcommand{\papertext}[1]{#1}
\newcommand{\techreporttext}[1]{}

\newcommand{\calD}{\mathcal{D}\xspace}

\newenvironment{denselist}{
    \begin{list}{\small{$\bullet$}}%
    {\setlength{\itemsep}{0ex} \setlength{\topsep}{0ex}
    \setlength{\parsep}{0pt} \setlength{\itemindent}{0pt}
    \setlength{\leftmargin}{1.5em}
    \setlength{\partopsep}{0pt}}}%
    {\end{list}}

\makeatletter
\def\@copyrightspace{\relax}
\makeatother

\begin{document}

\title{Web Source Evaluation}
\numberofauthors{3} 
\author{
\alignauthor
Manas Joglekar\\
       \affaddr{Stanford University}\\
%       \affaddr{353 Serra Mall}\\
%	   \affaddr{Stanford, California 94305}\\
       \email{manasrj@stanford.edu}
\alignauthor
Hector Garcia-Molina\\
       \affaddr{Stanford University}\\
%       \affaddr{353 Serra Mall}\\
%	   \affaddr{Stanford, California 94305}\\
       \email{hector@cs.stanford.edu}
\alignauthor 
Aditya Parameswaran\\
       \affaddr{University of Illinois (UIUC)}\\
%       \affaddr{Champaign, Illinois 61820}\\
       \email{adityagp@illinois.edu}
}
\maketitle

\begin{abstract}
\end{abstract}

\section{Problem Setting(new)}
Our database consists of a single table $Z$, which we want to populate. We also imagine there is a conceptual table $Z'$ that is fully populated. For instance, $Z$ may be a table with schema, (Country, President), and only a few tuples filled in. Then $Z'$ is a table that contains all countries and their presidents. We say a tuple $t$ is `correct' if it is contained in $Z'$. 

We have a given set of data sources $s_1, s_2, ... s_m$. A source can be an online table, a document, or a webpage. We run extractors on every source to get candidate tuples. A candidate tuple is a tuple which we consider as being likely to be correct, though we are not sure of its correctness. We extract several candidate tuples for $Z$ from each of these sources, with each tuple possibly coming from multiple sources. Let $t_1, t_2, ... t_n$ be the candidate tuples extracted. We say source $s_i$ `output' tuple $t_j$ if $t_j$ was obtained by running an extractor on $s_i$. We also say a source $s_i$ is correct on a tuple $t_j$ if either $t_j$ is correct and $s_i$ outputs it, or if $t_j$ is incorrect and $s_i$ does not output it. We define the boolean variable $b_{i,j}$ to be true if tuple $t_j$ was obtained from source $s_i$. For each $t_j$, we let $T_j$ be a boolean random variable that denotes whether of not $t_j$ is correct. 

Each source has a false positive rate and a false negative rate, which are themselves random variables. In addition, sources are not independent. For example, two webpages on the same site are more likely to have several incorrect tuples in common. Thus even if the two webpages are individually correct on $0.8$ fraction of the tuples, the probability of both webpages being correct on any individual tuple may be more than $0.8 \times 0.8 = 0.64$. Modelling arbitrary  correlation between sources can be expensive, as the number of parameters required for $m$ sources is exponential in $m$. Thus we choose a route between the two extremes of assuming independence of all sources, and allowing arbitrary correlations in sets of sources. We assume that we are given a list of sources-groups $g_1, g_2, ...$, where each group $g$ is a set of sources that are known to be related to each other. For instance, there may be a $g$ for each website, that contains all pages on that website. Or there may be a $g$ for each author, consisting of all papers written by that author. We also assume there is one group that contains all sources, to account for wrong tuples that all sources have a good chance of containing (like the tuple (USA, Bush) for a `Current Presidents' table).

For each $g_k$, we have a false positive and false negative rate, given by two random variables $G_{k+},G_{k-} \in [0,1]$ respectively, that represents the `shared' part of the accuracy of sources belonging to $g_k$. We let $G_k$ denote the left stochastic matrix with columns $[1-G_{k-},G_{k-}]^T$, $[G_{k+},1-G_{k+}]^T$. We will elaborate on the effect of $G_k$ later. For each source $s_i$, we similarly have two random variables $S_{i+},S_{i-} \in [0,1]$ that denote the `individual' component of its false positive and false negative rate (individual meaning in addition to the $G_k$ parts). We can define matrix $S_i$ analogously to $G_k$. As an example of the difference between $G_k$ and $S_i$, if a set of papers was written by the same author, the $G_k$ of the author denotes the accuracy of the author's knowledge ($G_{k-}$ is the probability of the author missing a correct tuple, and $G_{k+}$ is that of the author assuming an incorrect tuple), while the $S_i$ values for the author's documents denote the probability with which the documents correctly reflect the author's knowledge ($S_{i-}$ is the probability of the document missing a tuple the author believes in, and $S_{i+}$ that of the document containing a tuple the author doesn't believe in). We assume a XXX prior over the values of $G_{k-}, G_{k+}, S_{i-}, S_{i+}$ for each $k$ and $i$. In general, we want the prior to reflect our knowledge that false negative probabilities are generally extremely low (because the number of false tuples is very high) while the false positive probabilities are higher (any correct tuple is likely to not appear in several sources).

Consider any tuple $t_j$. We use the random variable $T \in [0,1]$ to denote the prior probability of any $t_j$ being correct (prior meaning prior to looking at any source outputs). Each $t_j$ has one random variable $T_j$ that says whether $t_j$ is correct or not. $T_j$ can take two values which are both column matrices: $[1,0]^T$ which we also refer to as `true', and $[0,1]^T$ which we refer to as `false'. Thus $P(T_j = \text{true}) = T$ before conditioning on any other information. Now for each source group $g_k$, the probability that $g_k$ `believes' in tuple $t_j$ is given by the matrix product $G_kT_j$. We use the boolean random variable $T_{j,k}$ to denote whether or not $g_k$ believes in $t_j$ (which again takes value $[1,0]^T$ standing for `true', or $[0,1]^T$ which stands for `false'). For any source $s_i$, group $g_k$ containing $s_i$, and any tuple $t_j$, the probability that $s_i$ `believes' in $t_j$ via group $g_k$ is given by $S_iT_{j,k}$. We use the random variable $T_{j,k,i}$ to denote whether or not $s_i$ believes in $t_j$ via $g_k$. Finally, we wish to assume that each source $s_i$ outputs a tuple $t_j$ is and only if its believes in $t_j$ via some group containing $t_j$. That is, if and only if $\lor_{k : s_i \in g_k} T_{j,k,i}$. But we instead assume that there is a fixed small $\epsilon$ such that a source outputs a tuples with $\epsilon$ probability if $\lor_{k : s_i \in g_k} T_{j,k,i}$ is false, and fails to output the tuple with $\epsilon$ probability if $\lor_{k : s_i \in g_k} T_{j,k,i}$ is true. The reason for not setting $\epsilon = 0$ is to make Gibb's sampling possible when actually solving the problem. We only get to observe whether a source outputs a tuple or not, and need to use that to deduce the values of other latent variables. 

%%%%%%%%%%%%%
% we need to consider both presence and absence of tuples. But for tuples that dont occur anywhere at all, we need to have some assumption, to sensibly calibrate false negative rates.

In addition to knowing which tuples were displayed, we may have knowledge about relations between certain tuples. For instance, a source may contain a line of text that can be interpreted as $(a,b)$ or $(a, b')$, but not both. In that case, we want a way to represent the fact that the probabilities of the tuples $(a, b)$ and $(a, b')$ being correct are negatively correlated. Or, we may know that say $A$ is a primary key for a table with columns $A,B$. Then two tuples $(a,b)$ and $(a,b')$ are incompatible, and again their probabilities are negatively correlated. In order to represent this fact, we create a set of tuple-groups $H_1, H_2, ..$ such that of all the tuples from any group, only one is correct, with high probability (the reason behind assuming high probability rather than certainty of at most one tuple being correct is to make our computation easier later). We assume that the probability penalty for conflicting tuples (belonging to a common tuple-group) being correct is some small constant $\epsilon$ per common tuple-group. 

Let $P_J$ denote the un-normalized joint probability distribution over all random variables. For any tuple $t_j$, let $s(t_j)$ denote the set of indices of sources that output $t_j$, and let $g(t_j)$ denote the set of indices of source-groups containing a source that output $t_j$. For any source $s_i$, let $g(s_i)$ denote the set of indices of source groups that contain $s_i$. 
Using $\overrightarrow{T}$ to denote the vector of random variables $T_1..T_n$, $\overrightarrow{S}$ for $S_1..S_m$, $\overrightarrow{G}$ for $G_1, ... G_k$, $\overrightarrow{T_S}$ for $T_{1, s_{i_1}}, ..$, $\overrightarrow{T_G}$ for $T_{1, g_{k_1}}, ..$, $P$ is given by:
\begin{align*} 
& P_J(\overrightarrow{T}, \overrightarrow{T_S}, \overrightarrow{T_G}, \overrightarrow{S}, \overrightarrow{G}) =
\\& (\prod_{j=1}^{n} P(T_j) (\prod_{i\in s(t_j)} P(T_{j, s_i})) (\prod_{k\in g(t_j)} P(T_{j, s_i})) \times 
\\& \prod_{i\in s(t_j)} \epsilon^{I(T_j \oplus T_{j, s_i} \oplus(\bigoplus_{k\in g(s_i)} T_{j, g_k})))}
\\& \prod_{l} \prod_{1 \leq j_1 < j_2 \leq n} \epsilon^{I(T_{j_1} \land T_{j_2} \land (t_{j_1}\in H_l) \land (t_{j_2} \in H_l)})
\end{align*}
where $I$ is an indicator function.



\section{Problem Setting(old)}
Our database consists of a single table $T$, which we want to populate. We also imagine there is a conceptual table $T'$ that is fully populated. For instance, $T$ may be a table with schema, (Country, President), and only a few tuples filled in. Then $T'$ is a table that contains all countries and their presidents. We say a tuple $t$ is `correct' if it is contained in $T'$. 

We have a given set of data sources $s_1, s_2, ... s_m$. A source can be an online table, a document, or a webpage. We run extractors on every source to get candidate tuples. A candidate tuple is a tuple which we consider as being likely to be correct, though we are not sure of its correctness. We extract several candidate tuples for $T$ from each of these sources, with each tuple possibly coming from multiple sources. Let $t_1, t_2, ... t_n$ be the candidate tuples extracted. We say source $s_i$ `output' tuple $t_j$ if $t_j$ was obtained by running an extractor on $s_i$. We also say a source $s_i$ is correct on a tuple $t_j$ if either $t_j$ is correct and $s_i$ outputs it, or if $t_j$ is incorrect and $s_i$ does not output it. We define the boolean variable $b_{i,j}$ to be true if tuple $t_j$ was obtained from source $s_i$. For each $t_j$, we let $T_j$ be a boolean random variable that denotes whether of not $t_j$ is correct. 

Each source has some accuracy level, which is itself a random variable. In addition, sources are not independent. For example, two webpages on the same site are more likely to have several incorrect tuples in common. Thus even if the two webpages are individually correct on $0.8$ fraction of the tuples, the probability of both webpages being correct on any individual tuple may be more than $0.8 \times 0.8 = 0.64$. Modelling arbitrary  correlation between sources can be expensive, as the number of parameters required for $m$ sources is exponential in $m$. Thus we choose a route between the two extremes of assuming independence of all sources, and allowing arbitrary correlations in sets of sources. We assume that we are given a list of sources-groups $g_1, g_2, ...$, where each group $g$ is a set of sources that are known to be related to each other. For instance, there may be a $g$ for each website, that contains all pages on that website. Or there may be a $g$ for each author, consisting of all papers written by that author. Then for each $g_k$, we define a random variable $G_k \in [0,1]$ that represents the `shared' part of the accuracy of sources belonging to $g_k$. We will elaborate on $G_k$ later. For each source $s_i$, we have a random variable $S_i \in [0,1]$ that denotes the `individual' component of its accuracy (individual meaning in addition to the $G_k$ parts). For example, if a set of papers was written by the same author, the $G_k$ denotes the accuracy of the author's knowledge, while the $S_i$ values for the author's documents denote the probability with which they correctly reflect the author's knowledge.

Consider any tuple $t_j$, suppose it it output by sources $s_{i_1}, s_{i_2}, ... $ and the source-groups $g_{k_1}, g_{k_2}, ...$ (a tuple is output by a source group if it is output by at least one source from that source-group). Then we create one new boolean random variables per tuple-source pair, and per tuple-group pair. That is, for $T_j$, we create boolean random variables $T_{j, s_{i_1}}, T_{j, s_{i_2}}, ...$ and $T_{j,g_{k_1}}, T_{j, g_{k_2}}, ...$. $T_{j, s_{i_1}}$ tells us whether source $s_{i_1}$ made an error on tuple $t_j$. 

Now consider the following causal model. For each tuple $t_j$, the random variable $T_j$ is first set to true with some fixed prior probability $T$ (this corresponds to whether the tuple is actually correct or not). Then, each existing $T_{j, g_k}$ is set to true with probability $G_k$, independent of all other variables. Similarly, each existing $T_{j, s_i}$ is set to true with probability $S_i$. A tuple $T_j$ is actually output by a source $S_i$ if the value of $T_j \oplus T_{j, s_i} \oplus(\bigoplus_{k} T_{j, g_k})$ is true. Since we can observe which sources have output which tuples, we can use that to estimate the values of the hidden variables $T_j$, $T_{j, s_i}$, and so on, and use those to estimate $S_i$ and $G_k$, which gives us source accuracy. Instead of assigning $0$ probability to the tuple being displayed when the $\oplus$ expression above evaluates to false, we give it a small probability $\epsilon$, to make computation easier later.

In addition to knowing which tuples were displayed, we may have knowledge about relations between certain tuples. For instance, a source may contain a line of text that can be interpreted as $(a,b)$ or $(a, b')$, but not both. In that case, we want a way to represent the fact that the probabilities of the tuples $(a, b)$ and $(a, b')$ being correct are negatively correlated. Or, we may know that say $A$ is a primary key for a table with columns $A,B$. Then two tuples $(a,b)$ and $(a,b')$ are incompatible, and again their probabilities are negatively correlated. In order to represent this fact, we create a set of tuple-groups $H_1, H_2, ..$ such that of all the tuples from any group, only one is correct, with high probability (the reason behind assuming high probability rather than certainty of at most one tuple being correct is to make our computation easier later). We assume that the probability penalty for conflicting tuples (belonging to a common tuple-group) being correct is some small constant $\epsilon$ per common tuple-group. 

Let $P_J$ denote the un-normalized joint probability distribution over all random variables. For any tuple $t_j$, let $s(t_j)$ denote the set of indices of sources that output $t_j$, and let $g(t_j)$ denote the set of indices of source-groups containing a source that output $t_j$. For any source $s_i$, let $g(s_i)$ denote the set of indices of source groups that contain $s_i$. 
Using $\overrightarrow{T}$ to denote the vector of random variables $T_1..T_n$, $\overrightarrow{S}$ for $S_1..S_m$, $\overrightarrow{G}$ for $G_1, ... G_k$, $\overrightarrow{T_S}$ for $T_{1, s_{i_1}}, ..$, $\overrightarrow{T_G}$ for $T_{1, g_{k_1}}, ..$, $P$ is given by:
\begin{align*} 
& P_J(\overrightarrow{T}, \overrightarrow{T_S}, \overrightarrow{T_G}, \overrightarrow{S}, \overrightarrow{G}) =
\\& (\prod_{j=1}^{n} P(T_j) (\prod_{i\in s(t_j)} P(T_{j, s_i})) (\prod_{k\in g(t_j)} P(T_{j, s_i})) \times 
\\& \prod_{i\in s(t_j)} \epsilon^{I(T_j \oplus T_{j, s_i} \oplus(\bigoplus_{k\in g(s_i)} T_{j, g_k})))}
\\& \prod_{l} \prod_{1 \leq j_1 < j_2 \leq n} \epsilon^{I(T_{j_1} \land T_{j_2} \land (t_{j_1}\in H_l) \land (t_{j_2} \in H_l)})
\end{align*}
where $I$ is an indicator function.

% xor and product make sense, but resulting logits are not factorizable, into a factor part and a source part. can use mutiplicative logits instead, but doesn't seem to have a good interpretation. or can create factors for each subset of each g, (so the number of factors and parameters is now exponential in the size of g). EDIT: Can sort of factorize, by adding the new hidden boolean variables defined above. Those vars have a solo factor that reflects the accuracies of sources, or source-groups, and there is an additional factor that relates them, via XOR or AND logical expression, to the displayed value (true). 

% Important below, justification of above design choices.
% To model fact that there are many 'false' tuples, so prob(showing|false tuple) is very low, while prob(not showing|true tuple) is not that low. To reflect this, prec/recall don't seem right, as they make no reference to unshown false tuples. So using actual conditional probabilities from previous sentence instead. What if multiple sources show a tuple, doesn't that guarantee that tuple is true due to low value of prob(showing|false)? Not necessarily, because the falseness may have come from the source-group variable (assuming sources showing the tuple belong to a common source-group), and so the low probability is taken only once, not multiple times. <- Actually, taking accuracy alone (based on #false tuple x false neg. rate) doesn't work. Works if one source outputs. But if two sources output a tuple, then in prob. the #false tuples is counted only once (in tuple prior) while false neg rate is counted twice (once per source). Thus the individual components of accuracy (#false tuples, false neg rate) matter. Need to model separately. And of course, false tuples with different false negative rates (US, bush vs US, manas). Actually,the (US,Bush) like tuples get taken care of by groups right? But what if they're output by two sources not in same group due to bad group-finding? Answer: We always have one group that contains all sources. 
% Seems hard to factor the conditional probs such that the factor weights are meaningful, and have equal values for equal things (like prior prob over all tuples should correspond to some shared factor weight). compromise by just having accuracies (instead of false pos/false neg) and only applying it to candidate tuples? So here's what I do. In the background, we have the full model with lots of false tuples, low false positive prob (but reasonable product of false pos. prob and numberof false tuples), higher false neg prob. So we have a low prior on each tuple. We could do the processing on each tuple (displayed and not displayed), and we can count a source not displaying a tuple as negative evidence. But becuase of low prior prob. we can ignore non-displayed tuples (as it takes the low false pos.probability event of a tuple being displayed in order to push it up from its low prior). And because of high false neg. prob (most sources don't get most tuples), we can ignore it when a source doesn't display a tuple. Thus our full scheme, with these approximations, reduces to the practised scheme of only taking displayed tuples, giving them a low prior prob., modifying it with source accuracy which is high (its like 1 - false pos. prob(?)) for sources which display it, and ignoring sources which don't display it. 

% taking only positive tuples still seems worrying. because it always seems on any tuples, all sources are going to be right or all are going to be wrong (if they have common-ish groups). So it seems always better to blame all mistakes on factors).

% new twist by aditya. instead of assuming all groups are given, try to predict groups based on sources making same errors? this may have been done, to some extent.
% Another thing we need to do (not quite a twist). There are correct tuples (US, Obama), wrong tuples (US, Manas), and slightly wrong tuples (US, Bush).

\section{Solution Sketch (old)}
Our problem involves two kinds of variables we need to estimate: (i) Boolean variables, such as the truth values of tuples, and the truth values of tuple-source or tuple-group variables ($T_{j,G_k}$), and (ii) Real number variables, which are accuracy scores of sources or source-groups. For the boolean variables, we want to find the \textit{marginal probability} of them being correct, which is itself a real number. 

Given a some training data (a set of correct and incorrect tuples for the table), we can solve this problem in a way similar to Deepdive~\cite{deepdive,Niu_deepdive:web-scale}. First, we explain some terms needed for the solution. Our joint probability distribution over the boolean variables as a \textit{factor graph}. A factor graph is a bipartite graph, with two types of nodes, \textit{variables} and \textit{factors}. On one side of the bipartite graph are variable nodes, each of which corresponds to a random variable whose value we wish to infer. In our case, we create a variable node for each of our boolean random variables ($T_j, T_{j, S_i}$, etc). A \textit{possible world} refers to an assignment to all the variable nodes in the graph. The other side of the bipartite graph has factor nodes. Each factor node is connected to one or more variable nodes, and represents a relation between their probabilities. For instance, if two tuples $T_{j_1}, T_{j_2}$ are mutually incompatible because of say, a primary key constraint, then we will construct a factor node that is connected to $T_{j_1}$ and $T_{j_2}$ to represent their negative correlation. Each factor node is associated with a boolean \textit{expression} involving the variable nodes connected to it, and a \textit{weight}. To continue the example above, say we have mutually incompatible tuples $T_{j_1}, T_{j_2}$, and a factor node $f$ connected to both of them. Then $f$ will be associated with the expression $T_{j_1} \land T_{j_2}$, and a large negative weight $w_f$. The interpretation of this is that in any possible world where the expression of $f$ evaluates to true, the probability of the resulting world is multiplied by $e^{w_f}$. In this case, because $w_f$ is a large negative weight, we will heavily penalize any assignment to the variable nodes that makes both $T_{j_1}$ and $T_{j_2}$ true. In general, the un-normalized probability of a possible world is obtained by multiplying the $e^{w_f}$ values for every factor whose expression evaluates to true in that world. 

For our problem, we set the variable nodes to the boolean random variables in $\overrightarrow{T}, \overrightarrow{T_S}, \overrightarrow{T_G}$. We have a factor for each of these variables, containing that variable as the expression. For instance, for $T_j$, there exists a factor that is connected to $T_j$ alone, and has expression $T_j$. We will talk about the weights of these factors later. For each tuple-group, for each pair of tuples $t_{j_1}, t_{j_2}$ in it, we create a factor connected to both tuples with the expression $T_{j_1} \land T_{j_2}$, and weight $\log(\epsilon)$. For each tuple $t_j$, we also create a factor connecting $T_j$ and all its tuple-source and tuple-source-group variables $T_{j, S_{i_1}}, .., T_{j, G_{k_1}}, ..$. The expression for this factor is $T_j \oplus T_{j, s_i} \oplus(\bigoplus_{k\in g(s_i)} T_{j, g_k}))$, and weight is $\log(\epsilon)$. Now we have the specify the weights of the factors with the single boolean variables. The weights for the factors $T_j$ correspond to the prior probability of a tuple being correct, the weight for $T_{j, S_i}$ for each $i$ corresponds to the accuracy of source $s_i$, and the weight for $T_{j, G_k}$ corresponds to the accuracy of source-group $s_k$. Since these accuracies are not known beforehand, we need to learn the weights for these factors. We will explain how the weights are learnt later. To begin with, we can initialize the weights to some random values. 

Given a factor graph, with the graph structure, expressions, and weights specified, we want to find the probability distribution of values for each variable node in the graph. Finding the exact probability distribution is intractable for several graphs, but we can estimate the probability distribution using Gibb's Sampling. That is, we start from a random possible world, and then change the value of variables in it one at a time, in accordance with the total probability distribution. If we do this for sufficiently many iterations, the probability with which we reach a possible world approaches the actual probability of that possible world according to the total probability distribution. Then by counting the fraction of sampled possible worlds in which a variable node $T$ was set to true, we get an estimate of the marginal probability of $T$ being true. 

For learning weights, we can use some training data, along with stochastic gradient descent. Unlike for most gold-standard based evaluations, we are not using only the training data for evaluating source accuracies. We may have a small amount of training data with a large amount of unlabelled data, and our procedure uses both of these to evaluate sources. 

\begin{comment}
Later:
Crowdsourcing with budget
Key constraints (part of tuple correlations?)
partial extraction
partial correctness.
\end{comment}

%\balance
{\small
\bibliographystyle{abbrv}
\bibliography{WebSourceQuality}  
}

\end{document}
